# -*- coding: utf-8 -*-
"""plant_disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17xxe9gCfuCGLed2HQqbSvu7QNx9e1ITd
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

from google.colab import drive
drive.mount('/content/drive')

import zipfile

zip_path = '/content/drive/Mydrive/ICT/dataset/PlantVillage.zip'
extract_path = '/content/drive/Mydrive/ICT/dataset/'

with zipfile.Zipfile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

"""#Data preprocessing

## Resize & Convert Images to Array
"""

import os # for interacting with the file system

data = []       #store the image arrays.
labels = []     #will store the corresponding category (class) names.

#These lists will later be converted into NumPy arrays to feed into a model.

image_size = 64     #Sets the target size for resizing images (64√ó64 pixels).

#Deep learning models require inputs of uniform size. Smaller size = faster training

dataset_path = "/content/drive/MyDrive/Colab Notebooks/internship project/PlantVillage"

for category in os.listdir(dataset_path):                     #Loops through each subfolder in the dataset.
    category_path = os.path.join(dataset_path, category)      # Forms the full path to the subfolder to access the images inside each category folder.
    for img in os.listdir(category_path):                     #Loops through each image file inside the category folder
        img_path = os.path.join(category_path, img)           # Builds the full path to the image file So it can be read using OpenCV.
        try:
            img_arr = cv2.imread(img_path)                    #Reads the image from the file.Returns a NumPy array representing the image.
            img_arr = cv2.resize(img_arr, (image_size, image_size))             #Resizes the image to 64√ó64 pixels -  Models like CNNs require fixed-size inputs. Resize ensures consistency
            data.append(img_arr)
            labels.append(category)
        except:
            pass

data = np.array(data) / 255.0                                 #Converts the list data into a NumPy array and normalizes the pixel values.

#Images in OpenCV have pixel values from 0 to 255.
#Dividing by 255.0 scales them to [0, 1], helps with model training(neural networks).

labels = np.array(labels)

"""##Label encoding"""

le = LabelEncoder()                               #Creates an instance of LabelEncoder
labels_encoded = le.fit_transform(labels)
# .fit(labels) learns the unique class labels
# .transform(labels) converts each string label into its corresponding number

"""##Train-test split"""

X_train, X_test, y_train, y_test = train_test_split(data, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded)

#stratify parameter ensures that the class distribution in your training and test sets matches the original dataset.

"""#Feature extraction -
#### for SVM and Random Forest
"""

#Instead of feeding raw image arrays (which are large), you're extracting simpler features (histogram of grayscale intensities) for classical ML models (like SVM, KNN, etc.).
#This is useful when you want to use machine learning without deep learning.

def extract_features(img):
    img_uint8 = (img * 255).astype(np.uint8)                            # Convert from float64 to uint8.

    #OpenCV's functions like cv2.cvtColor() expect image data in uint8 format in range [0, 255], so you scale it back.

    img_gray = cv2.cvtColor(img_uint8, cv2.COLOR_BGR2GRAY)              #Converts the image to grayscale (single channel)

    #only need intensity values (not color) to compute a histogram.

    hist = cv2.calcHist([img_gray], [0], None, [256], [0, 256])

    #Calculates a grayscale histogram:
    #img_gray: input image.
    #[0]: channel index (only 1 channel in grayscale).
    #None: no mask applied (use full image).
    #[256]: 256 bins (0 to 255 pixel values).
    #[0, 256]: range of pixel values.

    #How many pixels in the image have intensity 0, 1, 2, ..., 255

    #result is a 256√ó1 array showing how many pixels fall into each intensity bucket.

    return hist.flatten()                    #Flattens the 2D histogram array to 1D (shape: (256,))

X_features = np.array([extract_features(img) for img in data])        #Loops through all preprocessed images in data, extracts histogram features, and creates a 2D NumPy array

# Shape: (num_samples, 256)
# This is feature matrix X, which can now be used with classical ML models

# splitting features:
X_train, X_test, y_train, y_test = train_test_split(
    X_features, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded)
# splits the features (X_features) and encoded labels into training and testing sets

# Visualize histogram features
plt.figure(figsize=(12, 6))

# Plot 1: Average histogram across all images
plt.subplot(1, 2, 1)
avg_features = X_features.mean(axis=0)
plt.bar(range(len(avg_features)), avg_features)
plt.title('Average Feature Histogram (All Images)')
plt.xlabel('Pixel Intensity (0-255)')
plt.ylabel('Average Pixel Count')

# Plot 2: Feature distribution for first few samples
plt.subplot(1, 2, 2)
for i in range(min(5, len(X_features))):
    plt.plot(X_features[i], alpha=0.7, label=f'Image {i+1}')
plt.title('Individual Feature Histograms (First 5 Images)')
plt.xlabel('Pixel Intensity (0-255)')
plt.ylabel('Pixel Count')
plt.legend()

plt.tight_layout()
plt.show()

"""Left Plot: Average Feature Histogram (All Images)
What it shows:
This bar chart represents the average pixel count per intensity value (from 0 to 255) across all images in the dataset.

Insights:

The histogram is bell-shaped, peaking around pixel intensity 120‚Äì140, meaning most pixels in the dataset are medium brightness (neither too dark nor too bright).

There are few very dark pixels (near 0) and few very bright ones (near 255) ‚Äî the dataset mostly contains mid-range tones.

The shape suggests images are well-lit with moderate contrast, typical of natural leaf images¬†under¬†daylight.

Right Plot: Individual Feature Histograms (First 5 Images)
What it shows:
Line plots of pixel intensity distributions for the first 5 images in the dataset.
Each line represents the grayscale histogram of one image (Images 1 to 5).

X-axis: Pixel intensity (0 to 255)

Y-axis: Pixel count (how many pixels have each intensity)
 Image 1 (Light blue line)
Histogram is smooth, peaks around intensity 140‚Äì160.

Implies: This image is moderately bright, likely well-lit.

Suggests: Leaf is clearly visible, no harsh shadows.

‚úÖ Good image for classification.

üü£ Image 2 (Purple line)
Sharp spike near intensity 0 ‚Äî almost all pixels are very dark.

Then almost flat across the rest.

Implies:

Underexposed (dark) image.

Possibly a black or dark background.

Poor lighting or leaf is diseased and dark.

‚ùå Problematic without preprocessing ‚Äî the model may think dark = disease, even when it‚Äôs not.

üî¥ Image 3 (Red line)
Peak around intensity 130‚Äì150, smooth curve.

Similar to Image 1 but slightly darker.

‚úÖ Acceptable, probably a normal leaf image.

üü¢ Image 4 (Green line)
Two small peaks: one in the dark range (~30‚Äì50) and one in the midrange (~120).

Bimodal distribution ‚Äî might have:

Dark background + bright leaf.

Healthy + diseased areas in same image.

‚úÖ Interesting image. Worth inspecting manually.

üü† Image 5 (Orange line)
More uniform distribution (spread over intensities 50‚Äì200).

No sharp peaks.

Suggests:

Even lighting.

Might be slightly overexposed, or the leaf has consistent brightness.

‚úÖ Decent¬†for¬†training.

#Training ML model

## Model 1- Support Vector Machine (SVM)
"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import GridSearchCV
param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
svm_model = GridSearchCV(SVC(), param_grid, cv=5)
svm_model.fit(X_train, y_train)

# Evaluate
y_pred_svm = svm_model.predict(X_test)
print("üîπ SVM Accuracy:", accuracy_score(y_test, y_pred_svm))
print("üîπ Best Params:", svm_model.best_params_)
print("üîπ Classification Report:\n", classification_report(y_test, y_pred_svm))

"""##Model 2-Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

rf_model = RandomForestClassifier(n_estimators=100, random_state=52)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

print(" Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(" Classification Report (RF):\n", classification_report(y_test, y_pred_rf))

"""##Model 3-Custom CNN(using raw images)"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical

# Prepare data
X = data  # normalized already
y = to_categorical(labels_encoded)  # one-hot encoded labels

X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=labels_encoded
)

# CNN Model
cnn = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D(2, 2),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(y.shape[1], activation='softmax')  # number of classes
])

cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the CNN
cnn.fit(X_train_img, y_train_img, epochs=30, batch_size=32, validation_split=0.2)

# Evaluate
cnn_loss, cnn_acc = cnn.evaluate(X_test_img, y_test_img)
print(" CNN Accuracy:", cnn_acc)

print("Model Accuracies:")
print("CNN:", cnn_acc)
print("SVM:", acc_svm)
print("Random Forest:", acc_rf)

model_path = "/content/drive/MyDrive/ICT/cnn_model.h5"
cnn.save(model_path)
print(f"Model saved at {model_path}")

!pip install streamlit -q

!pip install gradio -q

import gradio as gr
import numpy as np
import cv2
from tensorflow.keras.models import load_model
from PIL import Image as PILImage

# Load your model and label encoder as before
cnn = load_model("/content/drive/MyDrive/ICT/cnn_model.h5")
class_labels = label_encoder.classes_

def predict_disease_ui(image):
    # Convert PIL image to OpenCV format
    img = np.array(image)
    img_cv2 = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

    # Preprocess
    img_resized = cv2.resize(img_cv2, (64, 64))
    img_resized = img_resized / 255.0
    img_input = np.expand_dims(img_resized, axis=0)

    # Predict
    predictions = cnn.predict(img_input)
    predicted_class = np.argmax(predictions[0])
    confidence = np.max(predictions[0])
    class_name = label_encoder.inverse_transform([predicted_class])[0]

    # Top 3
    top_indices = np.argsort(predictions[0])[::-1][:3]
    top_results = "\n".join(
        [f"{i+1}. {label_encoder.inverse_transform([idx])[0]} - {predictions[0][idx]:.2%}"
         for i, idx in enumerate(top_indices)]
    )

    result_text = (
        f"Class: {class_name}\n"
        f"Confidence: {confidence:.2%}\n\n"
        f"Top Predictions:\n{top_results}"
    )

    return result_text

# Gradio UI
gr.Interface(
    fn=predict_disease_ui,
    inputs=gr.Image(type="pil", label="Upload Leaf Image"),
    outputs=gr.Textbox(label="Prediction Results"),
    title="üåø Plant Leaf Disease Predictor",
    description="Upload an image of a plant leaf. The model will detect possible diseases and show the top predictions."
).launch(share=True)

from google.colab import files
from IPython.display import Image, display
import numpy as np
import cv2

def predict_disease():
    # Upload image
    uploaded = files.upload()

    for filename in uploaded.keys():
        # Display the uploaded image
        print(f"Uploaded image: {filename}")
        display(Image(filename))

        # Preprocess the image
        img = cv2.imread(filename)
        if img is None:
            print("Error: Could not read the image file.")
            return

        img = cv2.resize(img, (64, 64))  # Resize to match model input
        img = img / 255.0  # Normalize
        img = np.expand_dims(img, axis=0)  # Add batch dimension

        # Make prediction
        predictions = cnn.predict(img)
        predicted_class = np.argmax(predictions[0])
        confidence = np.max(predictions[0])

        # Get class name
        class_name = label_encoder.inverse_transform([predicted_class])[0]

        # Display results
        print("\nPrediction Results:")
        print(f"Class: {class_name}")
        print(f"Confidence: {confidence:.2%}")
        print("\nTop Predictions:")

        # Get top 3 predictions
        top_indices = np.argsort(predictions[0])[::-1][:3]
        for i, idx in enumerate(top_indices):
            print(f"{i+1}. {label_encoder.inverse_transform([idx])[0]} - {predictions[0][idx]:.2%}")

# Run the prediction function
print("Please upload an image of a plant leaf for disease prediction:")
predict_disease()